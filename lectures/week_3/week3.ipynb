{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week - 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 05 - 21.01.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about heuristics...\n",
    "\n",
    "In order for the heuristic to be a proper one, $f$, where $f(n)=g(n)+h(n)$ has to be monotonic... \\\n",
    "$f(n):max{f(parent(n)), g(n)}+h(n)$ and $f(n)$ is path max correction... \\\n",
    "$h$ is monotonic if $h(n) \\le h(n') + c(n,a,n')$ \\\n",
    "If $h$ is monotonic, \\\n",
    "$f(n'):g(n')+h(n') = g(n)+h(n') + c(n,a,n') \\ge g(n) +h(n) = f(n)$ \\\n",
    "this will result f is monotonic along the path, i.e., if h is monotonic, then there's no need for path mx correction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for an optimal A* search \\\n",
    "Effective branching factor: 1+b* + b*^2 + ... + b*^d = N+1... we say that the A* search is efficient when b* is close to 1... and the heuristic defines the efficiency of the A* search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideer the 8 tiles problem...\n",
    "\n",
    "h<sub>i</sub> : misplaced tiles, \\\n",
    "h<sub>r</sub> : manhattan distance ($|x_1 - x_2|+|y_1 - y_2|$) \\\n",
    "If $h_1(n) \\ge h_2(n) \\forall n$, here we say that $h_1$ is a dominant heuristic as $h_2$ expands more nodes than $h_1$ \\\n",
    "This is  in a generic sense but not forn this case... here $h_2 \\ge h_1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the question comes how do we generate these heuristics? \\\n",
    "For a siple heuristic, generation takes less time and searching requires a lot and the opposite for h* \\\n",
    "This is the reason we use something called pattern databases... \\\n",
    "We create a databases of samller problems with the solutions of the exact cost of solving it... \\\n",
    "Then we store these subproblem... and once we do the larger problem when we reach a particular configuration we do a look up from the database and then the heuristic is the subproblem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative deepening A* search: \\\n",
    "A* is only a threshold for the dfs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lab 1: \\\n",
    "> We are in a 4x4 grid.... some of the grids have walls \\\n",
    "> we have gold in some places and there is an exit state \\\n",
    "> there's a seq to pick up gold... all he knows if to go and pick up gold at (i,j) \\\n",
    "> Now the moment it reaches the goal, it knows about the next goal state and finally the exit state \\\n",
    "> Solution must essentially be all the paths..\n",
    "> TO DO: \\\n",
    "> We need to write the child gen function that takes the pos and gives the children \\\n",
    ">  Goal test function: implement bfs, dfs using only a list\n",
    "> in case there's no solution it should output the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Search:\n",
    "here the solution is the goal state but bot the path taken..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hill climbing search** - \n",
    "- **simulated annealing** ? watever..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 06 - 23.01.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond Classical Search:\n",
    "- goal itself is the solution, path to the goal is irrrelevant.\n",
    "- Ex: Travelling salesman problem...\n",
    "- state space: all possible configurations..\n",
    "- we are interested in findinag the goal, where goal is an optimal configuration\n",
    "- start from some configuration and we try to improve it\n",
    "- constant space (we're not keeping track of the past configs, or storing the future configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hill Climbing Search_:\n",
    "- efficient but incomplete\n",
    "- steepest aceent approach\n",
    "- greedy local algorithm\n",
    "- equivalent would be hill descending search and we use the steepest descent search... and we'll be using this in machine learning...\n",
    "- hill climbing algorithm\n",
    "    ```\n",
    "    hill_climbing_search:\n",
    "        node =  current.state:\n",
    "        loop do:\n",
    "            neighbors=cgf(node)\n",
    "            max_meighbor=arg_max{vlaue[neighbors]}\n",
    "            if value[max_neighbor]> or greater than equal to value[node]:\n",
    "                node=max_neighbor\n",
    "        conditions for the loop to terminate:\n",
    "            - the value of the max neighbor is less than the value of the node\n",
    "            - no neighbors\n",
    "            - ?\n",
    "    ```\n",
    "- ridge... where the hill climbing search fails\n",
    "- random sideways moves - when it is stuck at a shoulder... \n",
    "- ranodm restart hill climbing - when it is stuck at a local optimum... (this will be a complete search)\n",
    "- Stocastic hill climbing - if there are more than two states that are greater than the current state, we randomly go to one of the state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Simulated Annealing_:\n",
    "- we do some bad moves to escape from a local maxima\n",
    "- tries to include both hill climbing and random walk\n",
    "- inspires from annealing of material... or whatever\n",
    "- temp high $\\implies$ allow for random moves\n",
    "- temp low $\\implies$ hill climbing search\n",
    "- schedule [t] $\\rightarrow$ T (maps the iteration to temprature)\n",
    "-   ```\n",
    "    for t : 1 to float('inf') \n",
    "        T = schedule[t]\n",
    "        if T=0 then return the current state\n",
    "        next = a randomly selected successor of the current state\n",
    "        del e = value[next] = value[current]\n",
    "        if del e> 0 then current e next\n",
    "        else current  = next only with the probalility e^(del e/T)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_local beam search_:\n",
    "- where instead of keeping track of a single state, we keep track of k best states so far and do the search on these states\n",
    "- k is the size of the beam \n",
    "- and the exploration happens in parallel\n",
    "- an unfavourable case would be that all the states explore the same hill... so we add some stocasticity\n",
    "- stocastic beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
